"use strict";(self.webpackChunkmeso_net=self.webpackChunkmeso_net||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Request a MesoNET account","href":"/documentation/user-documentation/connectToMesonet","docId":"connectToMesonet"},{"type":"link","label":"Request access to a server","href":"/documentation/user-documentation/requestAccess","docId":"requestAccess"},{"type":"link","label":"Documentation Utilisateur pour Slurm","href":"/documentation/user-documentation/Doc_Utilisateur_Slurm","docId":"Doc_Utilisateur_Slurm"},{"type":"link","label":"MesoNET user documentation","href":"/documentation/user-documentation/","docId":"README"},{"type":"category","label":"juliet","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Apptainer","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Nvidia NGC catalog","href":"/documentation/user-documentation/juliet/Apptainer/Building_NGC_Containers","docId":"juliet/Apptainer/Building_NGC_Containers"}]},{"type":"link","label":"Documentation Utilisateur pour Slurm","href":"/documentation/user-documentation/juliet/Doc_Utilisateur_Slurm","docId":"juliet/Doc_Utilisateur_Slurm"},{"type":"category","label":"MPI","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Building a CUDA-aware Open MPI  library on an Infiniband cluster","href":"/documentation/user-documentation/juliet/MPI/MPI_CUDA_aware_Installation_Guide","docId":"juliet/MPI/MPI_CUDA_aware_Installation_Guide"},{"type":"link","label":"Apptainer and MPI implementations","href":"/documentation/user-documentation/juliet/MPI/MPI_and_Apptainer","docId":"juliet/MPI/MPI_and_Apptainer"},{"type":"link","label":"Tunning and testing CUDA-Aware MPI communication libraries","href":"/documentation/user-documentation/juliet/MPI/Tunning_MPI_CUDA_Aware","docId":"juliet/MPI/Tunning_MPI_CUDA_Aware"}]},{"type":"category","label":"benchmarks","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"NVIDIA HPC-Benchmarks","href":"/documentation/user-documentation/juliet/benchmarks/Nvidia_HPC_Benchmarks","docId":"juliet/benchmarks/Nvidia_HPC_Benchmarks"}]}]}]},"docs":{"connectToMesonet":{"id":"connectToMesonet","title":"Request a MesoNET account","description":"You need to create a MesoNET account to access all MesoNET services.","sidebar":"tutorialSidebar"},"Doc_Utilisateur_Slurm":{"id":"Doc_Utilisateur_Slurm","title":"Documentation Utilisateur pour Slurm","description":"1. Introduction \xe0 Slurm","sidebar":"tutorialSidebar"},"juliet/Apptainer/Building_NGC_Containers":{"id":"juliet/Apptainer/Building_NGC_Containers","title":"Nvidia NGC catalog","description":"NVIDIA NGC catalog provides a set of containerized environments (e.g. software development kits) you can use in deep learning, machine learning, and high-performance computing projects. Certain containers also include pre-trained models and HPC applications, optimized for running on Nvidia GPUs.","sidebar":"tutorialSidebar"},"juliet/benchmarks/Nvidia_HPC_Benchmarks":{"id":"juliet/benchmarks/Nvidia_HPC_Benchmarks","title":"NVIDIA HPC-Benchmarks","description":"Nvidia HPC-Benchmarks represent a collection of three classical benchmarks (HPL, HPL-AI, and HPCG) optimized for Nvidia accelerated systems. HPL and HPL-AI are both implementations of the well-known Linpack benchmark. The difference is that HPL solves a dense linear system in double precision (64 bits) arithmetic and HPL-AI in mixed precision arithmetic. Opting for mixed precision can drastically decrease the execution time. It can be useful for applications that can achieve desired results at lower floating-point precision formats (e.g. machine learning). HPCG is another well-known benchmark. It performs a fixed number of multigrid preconditioned conjugate gradient iterations using double-precision arithmetics.","sidebar":"tutorialSidebar"},"juliet/Doc_Utilisateur_Slurm":{"id":"juliet/Doc_Utilisateur_Slurm","title":"Documentation Utilisateur pour Slurm","description":"1. Introduction \xe0 Slurm","sidebar":"tutorialSidebar"},"juliet/MPI/MPI_and_Apptainer":{"id":"juliet/MPI/MPI_and_Apptainer","title":"Apptainer and MPI implementations","description":"There are two main ways of launching MPI applications with apptainer, known as Hybrid and Bind models. The Hybrid model involves the use of two MPI libraries: the MPI installed by the administrator on the host-side, and the MPI installed inside the container. Both libraries work in tandem to instantiate the job. Hence, the MPI used to compile the application in the container must be compatible with the version of MPI available on the host. In the case of the Bind model, we mount the host MPI into the container, without having any MPI library inside the container. The two models, along with their advantages and drawbacks are described in the Apptainer User Guide.","sidebar":"tutorialSidebar"},"juliet/MPI/MPI_CUDA_aware_Installation_Guide":{"id":"juliet/MPI/MPI_CUDA_aware_Installation_Guide","title":"Building a CUDA-aware Open MPI  library on an Infiniband cluster","description":"Historically, on Infiniband clusters, Open MPI was built with the openib BTL support, enabled when Open MPI is configured --with-verbs. The openib BTL became deprecated in favor of the Unified Communication X (UCX) PML. Hence, the current documentation shows some guidelines on how to install a CUDA-Aware Open MPI library with UCX. Note that all the examples used in this document were run on juliet supercomputer.","sidebar":"tutorialSidebar"},"juliet/MPI/Tunning_MPI_CUDA_Aware":{"id":"juliet/MPI/Tunning_MPI_CUDA_Aware","title":"Tunning and testing CUDA-Aware MPI communication libraries","description":"For testing the performance of a CUDA-Aware OpenMPI installation instance, we can use the well-known OSU benchmarks. We can also hand-tune the MPI runs via several UCX environment variables. Below we show some examples that highlight the impact of tunning options on the communication performance.","sidebar":"tutorialSidebar"},"README":{"id":"README","title":"MesoNET user documentation","description":"Welcome to MesoNET documentation for users","sidebar":"tutorialSidebar"},"requestAccess":{"id":"requestAccess","title":"Request access to a server","description":"1) You need a validated MesoNET account. You can find the steps to obtain one here.","sidebar":"tutorialSidebar"}}}')}}]);