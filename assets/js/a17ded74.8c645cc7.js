"use strict";(self.webpackChunkmesodocs=self.webpackChunkmesodocs||[]).push([[8851],{4137:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>b});var r=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var i=r.createContext({}),u=function(e){var n=r.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},p=function(e){var n=u(e.components);return r.createElement(i.Provider,{value:n},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},d=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=u(t),d=a,b=m["".concat(i,".").concat(d)]||m[d]||c[d]||o;return t?r.createElement(b,l(l({ref:n},p),{},{components:t})):r.createElement(b,l({ref:n},p))}));function b(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,l=new Array(o);l[0]=d;var s={};for(var i in n)hasOwnProperty.call(n,i)&&(s[i]=n[i]);s.originalType=e,s[m]="string"==typeof e?e:a,l[1]=s;for(var u=2;u<o;u++)l[u]=t[u];return r.createElement.apply(null,l)}return r.createElement.apply(null,t)}d.displayName="MDXCreateElement"},835:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>u});var r=t(7462),a=(t(7294),t(4137));const o={title:"Lancer un calcul",sidebar_position:4},l="Comment lancer un calcul sur Turpan ?",s={unversionedId:"arch_exp/turpan/jobs",id:"arch_exp/turpan/jobs",title:"Lancer un calcul",description:"Partition / global = 3 jobs max par utilisateur :",source:"@site/docs/arch_exp/turpan/jobs.md",sourceDirName:"arch_exp/turpan",slug:"/arch_exp/turpan/jobs",permalink:"/documentation/user-documentation/arch_exp/turpan/jobs",draft:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Lancer un calcul",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Le stockage",permalink:"/documentation/user-documentation/arch_exp/turpan/stockage"},next:{title:"Environnement de d\xe9veloppement",permalink:"/documentation/user-documentation/arch_exp/turpan/softenv"}},i={},u=[{value:"Comment lancer un script <code>sbatch</code> ?",id:"comment-lancer-un-script-sbatch-",level:2},{value:"Obtenir des informations sur un job",id:"obtenir-des-informations-sur-un-job",level:2}],p={toc:u},m="wrapper";function c(e){let{components:n,...t}=e;return(0,a.kt)(m,(0,r.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"comment-lancer-un-calcul-sur-turpan-"},"Comment lancer un calcul sur Turpan ?"),(0,a.kt)("p",null,"Partition / global = 3 jobs max par utilisateur :"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"small")," : exclusive, 2 jobs max, pas plus de 6 noeuds par jobs, max walltime par job 4H"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"big")," : exclusive, 1 job max, pas plus de 13 noeuds par jobs, max walltime par job 2H"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"full")," : exclusive, 1 job max, au moins 14 noeuds par jobs, max walltime par job 20H"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"shared")," : non exclusive, 2 jobs max, pas plus de 1 GPU, 40 cpu et 256G ram par jobs, max walltime par job 4H"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"visu")," : non exclusive, 1 job max, max 50Go RAM max 8 cpu par job, max walltime par job 4H")),(0,a.kt)("p",null,"Afin de ne pas monopoliser l\u2019ensemble des noeuds du cluster en journ\xe9e :"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'la partition "full" est activ\xe9e du lundi au vendredi \xe0 18H00'),(0,a.kt)("li",{parentName:"ul"},'la partition "full" est d\xe9sactiv\xe9e du lundi au jeudi ainsi que le dimanche \xe0 partir de 22H00')),(0,a.kt)("p",null,'Lorsque la partition est d\xe9sactiv\xe9e, les soumissions sont possibles, mais les jobs sont suspendus jusqu\u2019\xe0 l\u2019activation de la partition. A la d\xe9sactivation, les jobs RUNNING sur la partition "full" ne sont pas arr\xeat\xe9s.'),(0,a.kt)("h2",{id:"comment-lancer-un-script-sbatch-"},"Comment lancer un script ",(0,a.kt)("inlineCode",{parentName:"h2"},"sbatch")," ?"),(0,a.kt)("p",null,"Exemple script exclusif, 2 n\u0153uds, 160 processeurs, le temps d'ex\xe9cution moins de 4H"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Shell"},"#!/bin/bash\n#SBATCH -N 2\n#SBATCH -n 160\n#SBATCH --gres=gpu:2 \n#SBATCH -p small\n#SBATCH --ntasks-per-node=80\n#SBATCH --time=00:10:00\n\nmodule purge\nmodule load gnu/11.2.0\nmodule load openmpi/gnu/4.1.4-gpu\n\nnodeset -e ${SLURM_JOB_NODELIST} | tr ' ' '\\n' > hostfile_${SLURM_JOBID}\nmpirun -hostfile ./hostfile_${SLURM_JOBID} -n 160 ./exec\n")),(0,a.kt)("p",null,"Exemple script shared, 1 n\u0153ud, 40 processeurs,  le temps d'ex\xe9cution moins de 4H"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Shell"},"#!/bin/bash\n#SBATCH -N 1\n#SBATCH -n 40\n#SBATCH --gres=gpu:1\n#SBATCH -p shared\n#SBATCH --ntasks-per-node=40\n#SBATCH --time=00:10:00\n\nmodule purge\nmodule load gnu/11.2.0\nmodule load openmpi/gnu/4.1.4-gpu\n\nmpirun -n 40 ./exec\n")),(0,a.kt)("h2",{id:"obtenir-des-informations-sur-un-job"},"Obtenir des informations sur un job"),(0,a.kt)("p",null,"Il est possible pour visualiser simplement des information sur son job d'utiliser la commande ",(0,a.kt)("inlineCode",{parentName:"p"},"jobinfo <jobid>")," :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Shell"},"$ jobinfo 6101\n\nJob Infos :\n                Name : Test partition small - 4 noeuds\n                User : marteau\n           Partition : small\n              NNodes : 4\n               Nodes : turpancomp[0-3]\n               State : COMPLETED\n              Submit : 2023-04-14T16:08:02\n               Start : 2023-04-14T16:08:02\n                 End : 2023-04-14T16:08:05\n   Reserved walltime : 04:00:00\n       Used walltime : 00:00:03\n       Used CPU time : 00:01.884\n% User Computation) : 0 % (00:00.658)\n      % System (I/O) : 100.00 % (00:01.225)\n        Mem reserved : 2.0T\n        Max Mem used : 24M\n      Max Disk Write : 0\n       Max Disk Read : 0\n  Energy consumption : 1W.h\n")),(0,a.kt)("p",null,"Utilis\xe9 \xe0 la fin d'un script sbatch, jobinfo donnera des informations tr\xe8s utilies si vous contactez le support :"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Shell"},'#!/bin/bash\n#SBATCH -N 2\n#SBATCH -n 160\n#SBATCH --gres=gpu:2 \n#SBATCH -p small\n#SBATCH --ntasks-per-node=80\n#SBATCH --time=00:10:00\n\n# Chargement des modules\nmodule purge\nmodule load gnu/11.2.0\nmodule load openmpi/gnu/4.1.4-gpu\n\n# Preparation de l\'environnement d\'execution\nmyProjectDir=/users/sysadmin/marteau/slurm-scripts/mpi_hello_world_project\nmyExec="mpi_hello_world"\nmyWorkDir="${SLURM_JOBID}"\nmkdir -p "${myWorkDir}"\ncd "${myWorkDir}"\ncp "${0}" .\ncp ${myProjectDir}/${myExec} .\n\nnodeset -e "${SLURM_JOB_NODELIST}" | tr \' \' \'\\n\' > "hostfile_${SLURM_JOBID}"\nmpirun -hostfile "./hostfile_${SLURM_JOBID}" -n 160 "./${myExec}"\n\njobinfo "${SLURM_JOBID}"\n')),(0,a.kt)("p",null,"Ce qui affiche dans la sortie slurm (",(0,a.kt)("inlineCode",{parentName:"p"},"slurm-<jobid>.out"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Shell"},"[...]Job Infos :\n                Name : partition-small-jobinfo.sbatch\n                User : marteau\n           Partition : small\n              NNodes : 2\n               Nodes : turpancomp[0-1]\n               State : RUNNING\n              Submit : 2023-04-17T17:58:37\n               Start : 2023-04-17T17:58:37\n                 End : Unknown\n   Reserved walltime : 00:10:00\n       Used walltime : 00:01:04\n       Used CPU time : 00:46.488\n % User Computation) : 41.00 % (00:19.439)\n      % System (I/O) : 58.00 % (00:27.049)\n        Mem reserved : 1008G\n        Max Mem used : 9.8G\n      Max Disk Write : 329M\n       Max Disk Read : 250M\n  Energy consumption : 3W.h\n\nDebug Infos :\n           BatchHost : turpancomp0\n             Command : /users/sysadmin/marteau/slurm-scripts/partition-small-jobinfo.sbatch\n              StdOut : /tmpdir/marteau/slurm-6154.out\n              StdErr : /tmpdir/marteau/slurm-6154.out\n             WorkDir : /tmpdir/marteau\n")),(0,a.kt)("p",null,"Note : Il peut \xeatre utile de mettre une petite temporisation avant la commande jobinfo pour permettre d'avoir les derni\xe8res valeurs de l'accounting slurm s'il est utilis\xe9 dans un script sbatch:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-Shell"},"sleep 10\njobinfo\n")))}c.isMDXComponent=!0}}]);